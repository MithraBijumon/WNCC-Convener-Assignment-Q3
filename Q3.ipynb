{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb7ce11f-4679-4a4f-bf34-b2e9d55983d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "from torch import optim as optim\n",
    "import torch.utils.data as data\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "97918d39-5a7c-4c34-aa5e-85a6bf2d9dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What is overfitting and underfitting?', 'What is the best site to practice CP?', 'What laptop is good for coding?', 'What is the difference between HTML and HTML5?', 'How do I solve the knapsack problem?', 'How do I detect a cycle in a graph?', 'How to analyze complexity in CP?', 'What are some useful STL functions?', 'How do I write a good README?', 'How do I balance college and tech learning?', 'What is open source licensing?', 'How do I connect frontend and backend?', 'How do I host a website on GitHub Pages?', 'How do I stay consistent with coding practice?', 'How do I prepare for tech interviews?', 'What are common ML algorithms?', 'How can I build a good portfolio?', 'How do I find tech internships?', 'What is dynamic programming?', 'What is continuous integration in open source?', 'How do I implement a binary search tree?', 'How do I tune hyperparameters?', 'How do I implement linear regression?', 'What is the role of a loss function?', 'What is Git and why is it used?', \"What's the difference between a stack and a queue?\", 'How do I optimize brute force solutions?', 'How do I make a responsive website?', 'What are good beginner open source projects?', 'How do I approach a greedy problem?', 'How do I evaluate an ML model?', 'What is the sieve of Eratosthenes?', 'What is modular arithmetic in CP?', 'How do I handle missing data?', 'How do I reverse a linked list?', 'What is a binary search problem?', 'What is the difference between DFS and BFS?', 'How do I tag an issue properly?', 'What is a REST API?', 'How do I manage routing in a web app?', 'How do I implement quicksort?', 'What is a pull request?', 'How do I start learning ML?', 'What are CSS Flexbox and Grid?', 'How do I approach a contest?', 'How do I make a good tech resume?', 'How do I use JavaScript to manipulate the DOM?', \"What does 'forking' a repo do?\", 'What are time and space complexity?', 'What are Git hooks?', 'How can I improve problem-solving skills?', 'What is memoization?', 'How do I network with tech communities?', 'What are React components?', 'What is cross-validation?', 'How do I resolve a merge conflict?', 'What is the difference between GET and POST?', 'How do I contribute to a GitHub repo?', 'How do I manage time under pressure?', 'What is the difference between supervised and unsupervised learning?', 'How to implement a linked list in C?', 'What is gradient descent in machine learning?', 'How to create a responsive navbar in React?', 'How do I optimize my code for faster execution?', 'What are some beginner-friendly open source projects?', 'What is the difference between HTTP and HTTPS?', 'Explain merge sort with an example.', 'What is the use of activation functions in neural networks?', 'How do I deploy a Node.js app on Heroku?', 'How to approach a dynamic programming problem?', 'Where can I find open source issues labeled \"good first issue\"?', 'How does the internet work?', 'What is a binary search tree?', 'What is backpropagation in neural networks?', 'How to manage routing in a React application?', 'What is the best strategy for solving Codeforces problems?', 'How do I contribute to a GitHub project?', 'What is the difference between RAM and ROM?', 'How to implement a stack using queues?', 'What is overfitting and how to prevent it?', 'How to build a to-do list using HTML, CSS, and JS?', 'What is memoization in programming?', 'How to fork and clone a repo in Git?', 'Explain the OSI model in networking.', 'What is the difference between a queue and a deque?', 'What is the ROC curve in classification problems?', 'How do I use Bootstrap in a web project?', 'How to use bitmasking in competitive programming?', 'How do I make a pull request?', 'What is cloud computing?', 'What is the time complexity of heap sort?', 'What is a confusion matrix?', 'How do I use useEffect in React?', 'What are the most common number theory tricks?', 'How do I set up SSH for GitHub?', 'What is a CPU and how does it work?', 'What is a graph and how to represent it?', 'What is the difference between classification and regression?', 'How to handle forms in React?', 'What is the difference between Git and GitHub?', 'What is a compiler?', 'How to reverse a linked list?', 'What are decision trees?', 'What is the virtual DOM?', 'What is a segment tree used for?', 'How to submit code on GitLab?', 'What is DNS and how does it work?', 'What is a trie and where is it used?', 'What is transfer learning?', 'How do I use flexbox in CSS?', 'What are Fenwick trees?', 'How to resolve merge conflicts?', 'What is multithreading?', 'How to implement depth-first search?', 'What is reinforcement learning?', 'How to use React Router?', 'What is two-pointer technique?', 'How do I license my project?', 'What is an IP address?', 'What is a heap?', 'What are CNNs used for?', 'How to use Tailwind CSS?', 'What is modular exponentiation?', 'What is a web server?', 'How to detect a cycle in a graph?', 'What is k-means clustering?', 'How to make responsive web pages?', 'What is a sliding window technique?', 'How do I push changes to a remote repo?', 'What is a DNS server?', 'What is a neural network?', 'What is the box model in CSS?', 'How to solve a problem with constraints?', 'What is a version control system?', 'What is latency in networks?', 'How to find the lowest common ancestor in a binary tree?', 'What is logistic regression?', 'How to build a contact form in HTML?', 'How to solve problems with combinatorics?', 'What is GitHub Actions?', 'What is HTTP status code 404?', 'What is a hash table?', 'What are hyperparameters?', 'How to create a portfolio website?', 'What is the knapsack problem?', 'How to find open source projects to contribute to?', 'What is an API?', 'What is a circular linked list?', 'What is precision and recall?', 'How to fetch data from an API in React?', 'What are greedy algorithms?', 'How to contribute to Hacktoberfest?', 'What is SSL/TLS?', 'What is the difference between technical and non-technical projects?', \"What's the difference between stack and queue?\", 'What is the difference between Codeforces and AtCoder?', 'How does a REST API work?', 'What is the DOM in JavaScript?', 'How can I participate in CodeCamp?', 'Where can I find WnCC event details?', 'What is gradient descent?', 'How do I manage state in React?', 'How do I participate in ICPC?', 'How do I contribute to an open-source project?', 'What is an issue tracker?', 'How do I implement a heap in Python?', 'What is the use of cross-validation?', 'How do I start with Codeforces?', 'Where can I find WnCC event recordings?', 'What are precision and recall?', 'How do I join WnCC?', 'How do I get mentorship at WnCC?', 'How do I debug my code efficiently?', 'What are the benefits of joining a tech club?', 'How do I improve my problem-solving skills?', 'What events does WnCC organize?', 'What is WnCC?', 'What is the time complexity of binary search?', 'What are some good GitHub repos for first-time contributors?', 'What are the applications of DFS?', 'Explain merge sort with example.', 'How do I fork a repository?', 'How do I practice for contests?', 'What is server-side rendering?', 'How do I create a responsive navbar?', 'How do you detect a cycle in a linked list?', 'What does `git merge` do?', 'What are graph traversal algorithms?', 'How do I center a div using CSS?', 'What are some good platforms for competitive programming?', 'How does a decision tree work?', 'What is the difference between `git pull` and `git fetch`?', 'What is Git and how is it used?', 'Where can I find beginner-friendly open-source projects?', 'How does Union-Find work?', 'Where can I get help with tech doubts?', 'What is the use of React hooks?', 'What is a good rating on CodeChef?', 'What is overfitting in machine learning?', 'Explain Kadaneâ€™s algorithm.', 'How do I deploy a website on GitHub Pages?', 'What is a virtual contest?', 'How do neural networks learn?', 'Explain the bias-variance tradeoff.', 'What are the most common competitive programming topics?', 'Can I attend WnCC sessions without registration?', 'What is the purpose of WnCC?', 'How do I deploy a Vue app on GitHub Pages?', 'Where can I find open source projects related to Scikit-learn?', 'What are the best practices for Firebase in web development?', 'How do I improve at dynamic programming in competitive programming?', 'Explain how Next.js works in frontend development.', 'What are some beginner-friendly open-source projects to contribute to?', 'How do I deploy a Vercel app on Vercel?', 'Why use Vercel in web applications?', 'Explain Quick Sort with an example.', 'Explain Kruskalâ€™s algorithm with an example.', 'Are there any events happening this week?', 'What is Decision Tree used for in Machine Learning?', 'What is the time complexity of Merge Sort?', 'Which online judges support dynamic programming?', 'How do I implement Dijkstraâ€™s algorithm in Python?', 'What is the best strategy to solve dynamic programming problems in contests?', 'Where can I find past WnCC event recordings?', 'Which online judges support greedy algorithms?', 'Why is Merge Sort preferred over other algorithms?', 'Explain how Vercel works in frontend development.', 'How do I improve at graphs in competitive programming?', 'Explain Dijkstraâ€™s algorithm with an example.', 'Why is Dijkstraâ€™s algorithm preferred over other algorithms?', 'What is the time complexity of Quick Sort?', 'Explain Binary Search with an example.', 'How does Linear Regression algorithm work?', 'Why is Kruskalâ€™s algorithm preferred over other algorithms?', 'Why is Quick Sort preferred over other algorithms?', 'How do I improve at number theory in competitive programming?', 'Explain Merge Sort with an example.', 'Where can I find open source projects related to TensorFlow?', 'Is Firefox accepting contributions currently?', 'How do I deploy a Next.js app on Netlify?', 'Where can I find open source projects related to Firefox?', 'Where can I practice segment trees problems?', 'How do I implement Binary Search in Python?', 'What is CNN used for in Machine Learning?', 'Is VSCode accepting contributions currently?', 'Which online judges support number theory?', 'What is the time complexity of Kruskalâ€™s algorithm?', 'Is Scikit-learn accepting contributions currently?', 'What is the difference between CNN and RNN?', 'How do I deploy a Vue app on Vercel?', 'How does PCA algorithm work?', 'Where can I practice greedy algorithms problems?', 'How do I implement Merge Sort in Python?', 'Can you explain the concept of PCA in ML?', 'What is the difference between Linear Regression and PCA?', 'What are the best practices for Vercel in web development?', 'What are the best practices for React in web development?', 'Where can I practice graphs problems?', 'Which online judges support graphs?', 'What is the best strategy to solve segment trees problems in contests?', 'Why is Binary Search preferred over other algorithms?', 'How do I deploy a Firebase app on Vercel?', 'What is the difference between Decision Tree and Linear Regression?', 'Can you explain the concept of Decision Tree in ML?', 'How do I get started with open source contributions?', 'Explain how Firebase works in frontend development.', 'Can you explain the concept of CNN in ML?', 'What is the difference between RNN and RNN?', 'What skills are needed to contribute to Firefox open-source project?', 'Which online judges support segment trees?', 'What is the time complexity of Dijkstraâ€™s algorithm?', 'What is the difference between Linear Regression and Linear Regression?', 'Is TensorFlow accepting contributions currently?', 'Why use Vue in web applications?', 'Where can I practice number theory problems?', 'What is the time complexity of Binary Search?', 'Where can I find open source projects related to Linux Kernel?', 'Why use Next.js in web applications?', 'Explain how React works in frontend development.', 'What is the difference between Linear Regression and Decision Tree?', 'What is PCA used for in Machine Learning?', 'What is RNN used for in Machine Learning?', 'Why use React in web applications?', 'How does CNN algorithm work?', 'How do I improve at greedy algorithms in competitive programming?', 'Why use Firebase in web applications?', 'What is the difference between Linear Regression and CNN?', 'What is the best strategy to solve graphs problems in contests?', 'How do I improve at segment trees in competitive programming?', 'What skills are needed to contribute to TensorFlow open-source project?', 'Can you explain the concept of RNN in ML?', 'How do I implement Quick Sort in Python?', 'What skills are needed to contribute to Scikit-learn open-source project?', 'How do I implement Kruskalâ€™s algorithm in Python?', 'Where can I practice dynamic programming problems?', 'Can you explain the concept of Linear Regression in ML?', 'How do I deploy a Vercel app on GitHub Pages?', 'What are the best practices for Vue in web development?', 'How does Decision Tree algorithm work?', 'Is Linux Kernel accepting contributions currently?', 'What is the difference between RNN and CNN?', 'How do I deploy a Next.js app on Vercel?', 'What is the difference between PCA and Linear Regression?', 'What skills are needed to contribute to Linux Kernel open-source project?', 'Explain how Vue works in frontend development.', 'What is the best strategy to solve greedy algorithms problems in contests?', 'How do I deploy a React app on Vercel?', 'What is the best strategy to solve number theory problems in contests?', 'What are the best practices for Next.js in web development?', 'What is Linear Regression used for in Machine Learning?', 'How do I deploy a Firebase app on Netlify?', 'Where can I find open source projects related to VSCode?', 'How do I deploy a Firebase app on GitHub Pages?', 'What is the difference between CNN and Linear Regression?', 'How do I deploy a React app on GitHub Pages?', 'How do I deploy a React app on Netlify?', 'What is the difference between Decision Tree and Decision Tree?', 'What is the difference between PCA and PCA?', 'What skills are needed to contribute to VSCode open-source project?', 'What is the difference between PCA and CNN?', 'What is the difference between Decision Tree and CNN?', 'What is the difference between PCA and Decision Tree?', 'How does RNN algorithm work?', 'What is the difference between RNN and PCA?', 'What is the difference between Decision Tree and PCA?', 'How do I deploy a Vue app on Netlify?', 'What is the difference between Decision Tree and RNN?', 'How do I deploy a Vercel app on Netlify?']\n"
     ]
    }
   ],
   "source": [
    "with open('C:\\Mithra\\Extra Curricular\\WNCC Assignment\\queries.csv', 'r') as file:\n",
    "    csvfile = csv.reader(file)\n",
    "    dataset = {}\n",
    "    for line in csvfile:\n",
    "        dataset[line[0]] = line[1]\n",
    "tr = list(dataset.keys())\n",
    "tr.remove(\"QUERY\")\n",
    "outputs = list(dataset.values())\n",
    "outputs.remove(\"CATEGORY\")\n",
    "ev = {}\n",
    "print(tr)\n",
    "\n",
    "max_seq_length = max(len(clean(s).split()) for s in tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1e836804-8191-4302-a8a2-bd197dadfca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Open Source': 0, 'DSA': 1, 'Web Development': 2, 'Machine Learning': 3, 'Competitive Programming': 4, 'General': 5}\n"
     ]
    }
   ],
   "source": [
    "for i, key in enumerate(set(outputs)):\n",
    "  ev[key] = i\n",
    "#ev.pop('CATEGORY')\n",
    "print(ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "a646b1d5-2487-4a1e-8644-0ef5fde1f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(sentence):\n",
    "    words = sentence.split()\n",
    "    length = len(words)\n",
    "    l = len(words[length-1])\n",
    "    for i in range(len(words)):\n",
    "        words[i] = words[i].lower()\n",
    "        if '-' in words[i]:\n",
    "            tmp = []\n",
    "            without = words[i].split('-')\n",
    "            tmp = words[:i]+without+words[i+1:]\n",
    "            words = tmp\n",
    "    if words[-1][-1] == \"?\":\n",
    "        words[-1] = words[-1][0:l-1]\n",
    "    for word in words:\n",
    "        if word in ( \"a\", \"an\", \"the\", \"is\", \"are\", \"was\", \"were\", \"in\", \"on\", \"at\", \"of\", \"for\", \"to\", \"from\", \"that\", \"which\", \"who\", \"what\", \"when\", \"where\", \"how\", \"do\", \"does\", \"did\", \"with\",\"and\", \"or\", \"but\", \"if\", \"then\", \"so\", \"not\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\",\"can\", \"could\", \"will\", \"would\", \"should\", \"may\", \"might\", \"must\", \"i\"):\n",
    "            words.remove(word)\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "e5fdba01-1cf0-4598-8aae-0a380c26efb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are some beginner friendly open source projects contribute\n"
     ]
    }
   ],
   "source": [
    "print(clean(\"What are some beginner-friendly open-source projects to contribute to?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "1c9ca9ad-689b-429c-9640-c8fb8373adb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def embed(vocab_size, emb_dim, sentence):\\n    tokens=[]\\n    for word in clean(sentence).split():\\n        tokens.append(word_to_id.get(word,1))\\n    embedding_layer = nn.Embedding(vocab_size,emb_dim)              #torch.nn.Embedding(num_embeddings, embedding_dim, padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False, _weight=None, _freeze=False, device=None, dtype=None)[source]\\n    token_ids = torch.tensor([tokens])\\n    print(token_ids.shape)\\n    embedded_output = embedding_layer(token_ids)\\n    print(embedded_output.shape)\\n    return embedded_output'"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_id = {\"<PAD>\":0, \"<UNK>\":1}\n",
    "id_to_word = {0:\"<PAD>\", 1:\"UNK\"}\n",
    "idx = 2\n",
    "\n",
    "for sentence in tr:\n",
    "    for word in clean(sentence).lower().split():\n",
    "        if word not in word_to_id:\n",
    "            word_to_id[word] = idx\n",
    "            id_to_word[idx] = word\n",
    "            idx += 1\n",
    "\n",
    "def tokenize(sentence,max_seq_length):\n",
    "    tokens=[]\n",
    "    for word in clean(sentence).split():\n",
    "        tokens.append(word_to_id.get(word,1))\n",
    "    if len(tokens) != max_seq_length:\n",
    "        no_of_padding = max_seq_length - len(tokens)\n",
    "        padding = [0]*no_of_padding                              #I had a problem with dimensions so i added passing to make all sentences of equal length\n",
    "        tokens.extend(padding)\n",
    "    token_ids = torch.tensor([tokens])\n",
    "    return token_ids\n",
    "\n",
    "l = []\n",
    "for sentence in tr:\n",
    "    l.append(tokenize(sentence,max_seq_length))\n",
    "src_data = torch.cat(l, dim=0)\n",
    "\n",
    "l = []\n",
    "for word in outputs:\n",
    "    l.append(ev[word])\n",
    "tgt_data = torch.tensor(l)\n",
    "\n",
    "\"\"\"def embed(vocab_size, emb_dim, sentence):\n",
    "    tokens=[]\n",
    "    for word in clean(sentence).split():\n",
    "        tokens.append(word_to_id.get(word,1))\n",
    "    embedding_layer = nn.Embedding(vocab_size,emb_dim)              #torch.nn.Embedding(num_embeddings, embedding_dim, padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False, _weight=None, _freeze=False, device=None, dtype=None)[source]\n",
    "    token_ids = torch.tensor([tokens])\n",
    "    print(token_ids.shape)\n",
    "    embedded_output = embedding_layer(token_ids)\n",
    "    print(embedded_output.shape)\n",
    "    return embedded_output\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "5e0e7254-f999-475e-a102-4a3410fa494c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l = []\\nfor word in outputs:\\n    l.append(tokenize(word))\\ntgt_data = torch.cat(l,dim=0)\\nprint(l)'"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"l = []\n",
    "for word in outputs:\n",
    "    l.append(tokenize(word))\n",
    "tgt_data = torch.cat(l,dim=0)\n",
    "print(l)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c5219e88-5294-4f1f-9cf7-682e5b8ed073",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "f58b94c6-0322-4424-8c34-4e96e87b47d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2, 4, 10])\n",
      "torch.Size([5, 2, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "A= torch.randn(5,10,8)          \n",
    "A=A.view(5,2,10,4)   #basically 5 sentences, 2 heads, 10 words each, dimension of each head = 4\n",
    "print(A.transpose(-2,-1).shape)\n",
    "B = torch.matmul(A,A.transpose(-2,-1))\n",
    "print(B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "844d43d0-53d7-463b-a926-206ae7f42606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2, 10, 4])\n"
     ]
    }
   ],
   "source": [
    "C=torch.matmul(B, A)\n",
    "print(C.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "8db2f909-7e41-4077-9b01-74a5d1b95c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "0d0c91fa-892f-4805-847b-b2529e93ed44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "430c2ff4-8c8e-4862-9974-9eca5972eed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [1.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [4.]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position = torch.arange(0, 5, dtype=torch.float).unsqueeze(1)\n",
    "position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c26e9e68-4220-43bb-a112-9154715e8de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'max_seq_length = 10\\nd_model = 64\\npe = torch.zeros(max_seq_length, d_model)\\nposition = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\\ndiv_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\\nprint(position)\\nprint(div_term)\\nprint(position*div_term)\\nprint(torch.sin(position * div_term).shape)\\nprint(torch.cos(position * div_term))\\nprint(pe[:, 0::2].shape)\\nprint(pe[:, 1::2].shape)'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"max_seq_length = 10\n",
    "d_model = 64\n",
    "pe = torch.zeros(max_seq_length, d_model)\n",
    "position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "print(position)\n",
    "print(div_term)\n",
    "print(position*div_term)\n",
    "print(torch.sin(position * div_term).shape)\n",
    "print(torch.cos(position * div_term))\n",
    "print(pe[:, 0::2].shape)\n",
    "print(pe[:, 1::2].shape)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8be35001-0235-4c7b-9ce3-47e93418f8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cfdd1812-4acc-458b-83be-6bf578c9fe4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class DecoderLayer(nn.Module):\\n    def __init__(self, d_model, num_heads, d_ff, dropout):\\n        super(DecoderLayer, self).__init__()\\n        self.self_attn = MultiHeadAttention(d_model, num_heads)\\n        self.cross_attn = MultiHeadAttention(d_model, num_heads)\\n        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\\n        self.norm1 = nn.LayerNorm(d_model)\\n        self.norm2 = nn.LayerNorm(d_model)\\n        self.norm3 = nn.LayerNorm(d_model)\\n        self.dropout = nn.Dropout(dropout)\\n\\n    def forward(self, x, enc_output, src_mask, tgt_mask):\\n        attn_output = self.self_attn(x, x, x, tgt_mask)\\n        x = self.norm1(x + self.dropout(attn_output))\\n        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\\n        x = self.norm2(x + self.dropout(attn_output))\\n        ff_output = self.feed_forward(x)\\n        x = self.norm3(x + self.dropout(ff_output))\\n        return x'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
    "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        return x\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "61e0c46f-b701-4f73-b864-a53e5ea5b88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        #self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        #self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src):  #, tgt):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        #tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
    "        #seq_length = tgt.size(1)\n",
    "        #nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n",
    "        #tgt_mask = tgt_mask & nopeak_mask\n",
    "        return src_mask #, tgt_mask\n",
    "\n",
    "    def forward(self, src): #, tgt):\n",
    "        src_mask = self.generate_mask(src)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
    "        #tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
    "\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "\n",
    "        \"\"\"dec_output = tgt_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\"\"\"\n",
    "\n",
    "        pooled = enc_output.mean(dim=1)\n",
    "        output = self.fc(pooled)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "4b457744-52e2-4778-a7c9-b1652de0a928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10])\n"
     ]
    }
   ],
   "source": [
    "V = torch.randn(5,10,8)\n",
    "W = V.mean(dim=2)\n",
    "print(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "aafa75e8-bf3d-4ae2-b928-b5a9ac5d95cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x = torch.randn(2,4,8)\\nprint(x)\\nfc = nn.Linear(8, 6)\\nx = x.mean(dim=1)\\nprint(x)\\nprint(x.shape)'"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"x = torch.randn(2,4,8)\n",
    "print(x)\n",
    "fc = nn.Linear(8, 6)\n",
    "x = x.mean(dim=1)\n",
    "print(x)\n",
    "print(x.shape)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "9d2f301a-640e-4c29-aea2-5e1e38a3aa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_size = len(word_to_id)\n",
    "tgt_vocab_size = 6\n",
    "d_model = 512\n",
    "num_heads = 16\n",
    "num_layers = 6\n",
    "d_ff = 2048\n",
    "dropout = 0.2\n",
    "\n",
    "transformer = Transformer(src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "d9127e95-cf7b-4fd1-9409-cfa2f26310e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([328])\n"
     ]
    }
   ],
   "source": [
    "print(tgt_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "d1abf901-e37d-43e1-b056-bcac75427b5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 1.7623809576034546\n",
      "Epoch: 2, Loss: 1.765493631362915\n",
      "Epoch: 3, Loss: 1.5453052520751953\n",
      "Epoch: 4, Loss: 1.5205286741256714\n",
      "Epoch: 5, Loss: 1.2736605405807495\n",
      "Epoch: 6, Loss: 1.195817232131958\n",
      "Epoch: 7, Loss: 1.1690993309020996\n",
      "Epoch: 8, Loss: 1.1120045185089111\n",
      "Epoch: 9, Loss: 0.9791858196258545\n",
      "Epoch: 10, Loss: 0.8450057506561279\n",
      "Epoch: 11, Loss: 0.8135510087013245\n",
      "Epoch: 12, Loss: 0.7711024284362793\n",
      "Epoch: 13, Loss: 0.6499886512756348\n",
      "Epoch: 14, Loss: 0.560408890247345\n",
      "Epoch: 15, Loss: 0.5222970247268677\n",
      "Epoch: 16, Loss: 0.4860163629055023\n",
      "Epoch: 17, Loss: 0.42542603611946106\n",
      "Epoch: 18, Loss: 0.3811836540699005\n",
      "Epoch: 19, Loss: 0.2979271709918976\n",
      "Epoch: 20, Loss: 0.2951813042163849\n",
      "Epoch: 21, Loss: 0.2822270691394806\n",
      "Epoch: 22, Loss: 0.2110579013824463\n",
      "Epoch: 23, Loss: 0.17536652088165283\n",
      "Epoch: 24, Loss: 0.1704508364200592\n",
      "Epoch: 25, Loss: 0.14611166715621948\n",
      "Epoch: 26, Loss: 0.11964844912290573\n",
      "Epoch: 27, Loss: 0.0966193750500679\n",
      "Epoch: 28, Loss: 0.08029880374670029\n",
      "Epoch: 29, Loss: 0.07138833403587341\n",
      "Epoch: 30, Loss: 0.08286795765161514\n",
      "Epoch: 31, Loss: 0.05228078365325928\n",
      "Epoch: 32, Loss: 0.03876874968409538\n",
      "Epoch: 33, Loss: 0.03818777948617935\n",
      "Epoch: 34, Loss: 0.03280987963080406\n",
      "Epoch: 35, Loss: 0.03946579992771149\n",
      "Epoch: 36, Loss: 0.045311301946640015\n",
      "Epoch: 37, Loss: 0.02251174859702587\n",
      "Epoch: 38, Loss: 0.02743745595216751\n",
      "Epoch: 39, Loss: 0.011971639469265938\n",
      "Epoch: 40, Loss: 0.01363303977996111\n",
      "Epoch: 41, Loss: 0.011012239381670952\n",
      "Epoch: 42, Loss: 0.015655260533094406\n",
      "Epoch: 43, Loss: 0.009974813088774681\n",
      "Epoch: 44, Loss: 0.00850746314972639\n",
      "Epoch: 45, Loss: 0.008762468583881855\n",
      "Epoch: 46, Loss: 0.01009251456707716\n",
      "Epoch: 47, Loss: 0.006639423314481974\n",
      "Epoch: 48, Loss: 0.005007751751691103\n",
      "Epoch: 49, Loss: 0.010836761444807053\n",
      "Epoch: 50, Loss: 0.00740732392296195\n",
      "Epoch: 51, Loss: 0.01139902789145708\n",
      "Epoch: 52, Loss: 0.00659128138795495\n",
      "Epoch: 53, Loss: 0.004580145236104727\n",
      "Epoch: 54, Loss: 0.008466806262731552\n",
      "Epoch: 55, Loss: 0.006702091544866562\n",
      "Epoch: 56, Loss: 0.003046242520213127\n",
      "Epoch: 57, Loss: 0.004919431637972593\n",
      "Epoch: 58, Loss: 0.004855843260884285\n",
      "Epoch: 59, Loss: 0.0026216967962682247\n",
      "Epoch: 60, Loss: 0.003439344232901931\n",
      "Epoch: 61, Loss: 0.005626649595797062\n",
      "Epoch: 62, Loss: 0.0027716816402971745\n",
      "Epoch: 63, Loss: 0.002907918067649007\n",
      "Epoch: 64, Loss: 0.0025244224816560745\n",
      "Epoch: 65, Loss: 0.0023063982371240854\n",
      "Epoch: 66, Loss: 0.004093183670192957\n",
      "Epoch: 67, Loss: 0.0018642055802047253\n",
      "Epoch: 68, Loss: 0.0022824439220130444\n",
      "Epoch: 69, Loss: 0.0021078356076031923\n",
      "Epoch: 70, Loss: 0.0025774757377803326\n",
      "Epoch: 71, Loss: 0.0013518796768039465\n",
      "Epoch: 72, Loss: 0.0011177575215697289\n",
      "Epoch: 73, Loss: 0.0013756246771663427\n",
      "Epoch: 74, Loss: 0.0014072839403524995\n",
      "Epoch: 75, Loss: 0.0018368682358413935\n",
      "Epoch: 76, Loss: 0.0010664324508979917\n",
      "Epoch: 77, Loss: 0.0019181857351213694\n",
      "Epoch: 78, Loss: 0.0015714257024228573\n",
      "Epoch: 79, Loss: 0.0012726326240226626\n",
      "Epoch: 80, Loss: 0.0021748701110482216\n",
      "Epoch: 81, Loss: 0.00120387296192348\n",
      "Epoch: 82, Loss: 0.0014558747643604875\n",
      "Epoch: 83, Loss: 0.0016172080067917705\n",
      "Epoch: 84, Loss: 0.00393820321187377\n",
      "Epoch: 85, Loss: 0.0030043674632906914\n",
      "Epoch: 86, Loss: 0.0014746369561180472\n",
      "Epoch: 87, Loss: 0.0017461827956140041\n",
      "Epoch: 88, Loss: 0.0007725858595222235\n",
      "Epoch: 89, Loss: 0.0010895621962845325\n",
      "Epoch: 90, Loss: 0.001196803990751505\n",
      "Epoch: 91, Loss: 0.001275394344702363\n",
      "Epoch: 92, Loss: 0.002355230739340186\n",
      "Epoch: 93, Loss: 0.0010541857918724418\n",
      "Epoch: 94, Loss: 0.0009079516748897731\n",
      "Epoch: 95, Loss: 0.0008775292080827057\n",
      "Epoch: 96, Loss: 0.0010209763422608376\n",
      "Epoch: 97, Loss: 0.001012898632325232\n",
      "Epoch: 98, Loss: 0.0029987164307385683\n",
      "Epoch: 99, Loss: 0.0009814176009967923\n",
      "Epoch: 100, Loss: 0.006038323510438204\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "transformer.train()\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    output = transformer(src_data)\n",
    "    #print(output.shape)\n",
    "    #print(output)\n",
    "    #print(output.contiguous().view(-1, tgt_vocab_size))\n",
    "    loss = criterion(output, tgt_data)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "791911bc-52cf-4830-9c8a-048cb73fd240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 3, 2, 4, 5])\n",
      "['DSA', 'Machine Learning', 'Web Development', 'Competitive Programming', 'General']\n",
      "How do I implement Dijkstra’s algorithm in Python? → DSA\n",
      "What is the difference between CNN and RNN? → Machine Learning\n",
      "How do I deploy a React app on Vercel? → Web Development\n",
      "What are some beginner-friendly open-source projects to contribute to? → Competitive Programming\n",
      "Where can I find past WnCC event recordings? → General\n"
     ]
    }
   ],
   "source": [
    "q = [\"How do I implement Dijkstra’s algorithm in Python?\", \"What is the difference between CNN and RNN?\", \"How do I deploy a React app on Vercel?\", \"What are some beginner-friendly open-source projects to contribute to?\", \"Where can I find past WnCC event recordings?\"]\n",
    "l = []\n",
    "for sentence in q:\n",
    "    l.append(tokenize(sentence,max_seq_length))\n",
    "val_src_data = torch.cat(l, dim=0)\n",
    "\n",
    "out = [\"DSA\", \"Machine Learning\", \"Web Development\", \"Open Source\", \"General\"]\n",
    "l = []\n",
    "for word in out:\n",
    "    l.append(ev[word])\n",
    "val_tgt_data = torch.tensor(l)\n",
    "\n",
    "transformer.eval()\n",
    "with torch.no_grad():\n",
    "    output = transformer(val_src_data)  # shape: [no_of_sentences, no_of_classes)\n",
    "    predicted_class = torch.argmax(output, dim=1)  #shape: [no_of_sentences]\n",
    "\n",
    "print(predicted_class)\n",
    "tmp = []\n",
    "for pred in predicted_class:\n",
    "    tmp.append(idx_to_label[pred.item()])\n",
    "predicted_class=tmp\n",
    "print(predicted_class)\n",
    "\n",
    "idx_to_label = {} #{'Open Source': 0, 'DSA': 1, 'Web Development': 2, 'Machine Learning': 3, 'Competitive Programming': 4, 'General': 5}\n",
    "for key, value in ev.items():\n",
    "    idx_to_label[value] = key\n",
    "for i, pred in enumerate(predicted_class):\n",
    "    print(f\"{q[i]} → {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "b09ffa8b-ce6a-452f-8b82-8ff3e6d57485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DSA', 'Machine Learning', 'Web Development', 'Open Source', 'General'] ['DSA', 'Machine Learning', 'Web Development', 'Competitive Programming', 'General']\n"
     ]
    }
   ],
   "source": [
    "print(out, predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "546c2aa7-d386-4595-9ed4-f64b12af5028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Open Source', 1: 'DSA', 2: 'Web Development', 3: 'Machine Learning', 4: 'Competitive Programming', 5: 'General'}\n"
     ]
    }
   ],
   "source": [
    "print (idx_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "d0ec5be3-effc-4118-8eb7-337b311f835f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'transformer.eval()\\n\\nev = [\"How do I implement Dijkstra’s algorithm in Python?\", \"What is the difference between CNN and RNN?\", \"How do I deploy a React app on Vercel?\", \"What are some beginner-friendly open-source projects to contribute to?\", \"Where can I find past WnCC event recordings?\"]\\nl = []\\nfor sentence in ev:\\n    l.append(tokenize(sentence))\\nval_src_data = torch.cat(l, dim=0)\\n\\nl = []\\nfor word in outputs:\\n    l.append(tokenize(word))\\ntgt_data = torch.cat(l,dim=0)\\n\\n\\nwith torch.no_grad():\\n\\n    val_output = transformer.forward()\\n    val_loss = criterion(val_output.contiguous().view(-1, tgt_vocab_size), val_tgt_data[:, 1:].contiguous().view(-1))\\n    print(f\"Validation Loss: {val_loss.item()}\")'"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"transformer.eval()\n",
    "\n",
    "ev = [\"How do I implement Dijkstra’s algorithm in Python?\", \"What is the difference between CNN and RNN?\", \"How do I deploy a React app on Vercel?\", \"What are some beginner-friendly open-source projects to contribute to?\", \"Where can I find past WnCC event recordings?\"]\n",
    "l = []\n",
    "for sentence in ev:\n",
    "    l.append(tokenize(sentence))\n",
    "val_src_data = torch.cat(l, dim=0)\n",
    "\n",
    "l = []\n",
    "for word in outputs:\n",
    "    l.append(tokenize(word))\n",
    "tgt_data = torch.cat(l,dim=0)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    val_output = transformer.forward()\n",
    "    val_loss = criterion(val_output.contiguous().view(-1, tgt_vocab_size), val_tgt_data[:, 1:].contiguous().view(-1))\n",
    "    print(f\"Validation Loss: {val_loss.item()}\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "1ca4c9c2-50e2-4c87-be1a-a09e928df5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Open Source', 1: 'DSA', 2: 'Web Development', 3: 'Machine Learning', 4: 'Competitive Programming', 5: 'General'}\n"
     ]
    }
   ],
   "source": [
    "print(idx_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "d40c8393-37a4-4b22-af1e-f407625cec2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Machine Learning': 66, 'Web Development': 63, 'Competitive Programming': 55, 'DSA': 54, 'Open Source': 50, 'General': 40})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "ab436107-bb48-4db1-8f16-e541b2431375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Open Source': 0, 'DSA': 1, 'Web Development': 2, 'Machine Learning': 3, 'Competitive Programming': 4, 'General': 5}\n"
     ]
    }
   ],
   "source": [
    "print(ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "be68cf7d-7821-4838-8370-1d20d7f47efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8\n"
     ]
    }
   ],
   "source": [
    "no_of_correct_predictions = 0\n",
    "for i in range(len(out)):\n",
    "    if out[i] == predicted_class[i]:\n",
    "        no_of_correct_predictions+=1\n",
    "Accuracy = no_of_correct_predictions / len(out)\n",
    "print(\"Accuracy: \", Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "b9d83d45-30ce-4d24-bc38-e6947e150738",
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions = []\n",
    "recalls = []\n",
    "F1_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "546e1cef-84e6-4bad-964a-3ac2b7c77554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(label, pred, tgt):\n",
    "    TP=FP=FN=0\n",
    "    for i in range(len(tgt)):\n",
    "        if pred[i]==label:\n",
    "            if pred[i]==tgt[i]:\n",
    "                TP+=1\n",
    "            else:\n",
    "                FP+=1\n",
    "        elif tgt[i]==label:\n",
    "            FN+=1\n",
    "    if TP+FP+FN==0:\n",
    "        print(f\"Can't evaluate due to non availability of data for {label}\")\n",
    "        Precision = Recall = F1\n",
    "    if TP+FP==0:\n",
    "        print(f\"Precision and F1 of {label} can't be calculated\")\n",
    "        Recall = TP/(TP+FN)\n",
    "        print(f\"Recall of {label}: {Recall}\")\n",
    "        Precision = F1 = 0\n",
    "    elif TP+FN ==0 :\n",
    "        print(f\"Recall and F1 of {label} can't be calculated\")\n",
    "        Precision = TP/(TP+FP)\n",
    "        print(f\"Precision of {label}: {Precision}\") \n",
    "        Recall = F1 = 0\n",
    "    else:\n",
    "        Precision = TP/(TP+FP)\n",
    "        Recall = TP/(TP+FN)\n",
    "        F1 = 2*(Precision*Recall)/(Precision+Recall)\n",
    "        print(f\"Precision of {label}: {Precision}\") \n",
    "        print(f\"Recall of {label}: {Recall}\") \n",
    "        print(f\"F1 of {label}: {F1}\") \n",
    "    return Precision, Recall, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "1b021d9e-a37d-4877-9dea-3e4cf2eb0984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision and F1 of Open Source can't be calculated\n",
      "Recall of Open Source: 0.0\n",
      "Precision of DSA: 1.0\n",
      "Recall of DSA: 1.0\n",
      "F1 of DSA: 1.0\n",
      "Precision of Web Development: 1.0\n",
      "Recall of Web Development: 1.0\n",
      "F1 of Web Development: 1.0\n",
      "Precision of Machine Learning: 1.0\n",
      "Recall of Machine Learning: 1.0\n",
      "F1 of Machine Learning: 1.0\n",
      "Recall and F1 of Competitive Programming can't be calculated\n",
      "Precision of Competitive Programming: 0.0\n",
      "Precision of General: 1.0\n",
      "Recall of General: 1.0\n",
      "F1 of General: 1.0\n"
     ]
    }
   ],
   "source": [
    "for key in ev:\n",
    "    precision, recall, F1 = compare(key, predicted_class, out)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    F1_scores.append(F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "7d4415fe-df04-4f80-a038-a22756db14c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 1.0, 1.0, 1.0, 0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "c79bf7e5-5c48-49ef-85a4-45bbf85c2117",
   "metadata": {},
   "outputs": [],
   "source": [
    "Macro_Precision = sum(precisions)/len(precisions)\n",
    "Macro_Recall = sum(recalls)/len(recalls)\n",
    "MacroF1 = sum(F1_scores)/len(F1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "2115dabd-8148-47c1-be87-c2c4b6affb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8\n",
      "Precision:  0.6666666666666666\n",
      "Recall:  0.6666666666666666\n",
      "F1 Score:  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", Accuracy)\n",
    "print(\"Precision: \", Macro_Precision)\n",
    "print(\"Recall: \", Macro_Recall)\n",
    "print(\"F1 Score: \", MacroF1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f46852f-5eb6-4650-b1a3-6faff63ee8e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
